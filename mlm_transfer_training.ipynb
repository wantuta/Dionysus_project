{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab37bf55-a349-44be-8a96-cbeacd8a69bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import random\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm  \n",
    "import os\n",
    "import torch.optim as optim\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e2dcd3-b9e5-4665-92ab-b401cd0b3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. GPU: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "#checking if CUDA is available and printing GPU details\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09409261-0493-434e-9bf9-687cd7589de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the dataset\n",
    "data = pd.read_csv('../mlm_transfer/ready_for_mlm_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4cbbb88-7681-4192-821d-6f52f10c591c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at altsoph/bert-base-ancientgreek-uncased and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#importing tokenizer and model for BERT MLM transfer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/bert-base-greek-uncased-v1\")\n",
    "model = BertForMaskedLM.from_pretrained(\"altsoph/bert-base-ancientgreek-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba0844fe-dfdf-44ed-a5a0-4d31005598f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               text\n",
      "0           0  δεινοί τινεσ εἰσὶ νουθετεῖν ἑτέρουσ ἀφε...\n",
      "1           1  οὐκ ἀμφοτέρων ἄρα τῶν καιρῶν διήμαρτον...\n",
      "2           2  ̔ μὲν ἐπίδειξισ οὐδαμῶσ εὐτυχὴσ οὐδὲ ...\n",
      "3           3  ̓́στι μὲν οὐ σμικρὸν, ὦ ἄνδρεσ σμυρναῖ...\n",
      "4           4  νόμοσ ἐστὶ τοῖσ ̔́λλησι παλαιὸσ, οἶμαι ...\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2e4789-5ba6-4fb8-ad2b-a29e9afe0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "783fdccd-497c-4a49-827d-5f02add5c4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>δεινοί τινεσ εἰσὶ νουθετεῖν ἑτέρουσ ἀφε...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>οὐκ ἀμφοτέρων ἄρα τῶν καιρῶν διήμαρτον...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>̔ μὲν ἐπίδειξισ οὐδαμῶσ εὐτυχὴσ οὐδὲ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>̓́στι μὲν οὐ σμικρὸν, ὦ ἄνδρεσ σμυρναῖ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>νόμοσ ἐστὶ τοῖσ ̔́λλησι παλαιὸσ, οἶμαι ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>̓σαῖοσ δὲ ὁ δημοσθένουσ καθηγησάμενοσ κ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>̔ητορική ἐστι δύναμισ τεχνικὴ πιθανοῦ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>περὶ δεινάρχου τοῦ ῥήτοροσ οὐδὲν εἰρ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>*************** δικανικοῖσ μὲν οὖν ο...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>‘δῶρόν τοι καὶ ἐγώ, τέκνον φίλε, τ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    δεινοί τινεσ εἰσὶ νουθετεῖν ἑτέρουσ ἀφε...\n",
       "1    οὐκ ἀμφοτέρων ἄρα τῶν καιρῶν διήμαρτον...\n",
       "2    ̔ μὲν ἐπίδειξισ οὐδαμῶσ εὐτυχὴσ οὐδὲ ...\n",
       "3    ̓́στι μὲν οὐ σμικρὸν, ὦ ἄνδρεσ σμυρναῖ...\n",
       "4    νόμοσ ἐστὶ τοῖσ ̔́λλησι παλαιὸσ, οἶμαι ...\n",
       "..                                                 ...\n",
       "154    ̓σαῖοσ δὲ ὁ δημοσθένουσ καθηγησάμενοσ κ...\n",
       "155      ̔ητορική ἐστι δύναμισ τεχνικὴ πιθανοῦ...\n",
       "156    περὶ δεινάρχου τοῦ ῥήτοροσ οὐδὲν εἰρ...\n",
       "157        *************** δικανικοῖσ μὲν οὖν ο...\n",
       "158       ‘δῶρόν τοι καὶ ἐγώ, τέκνον φίλε, τ...\n",
       "\n",
       "[159 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3260bb86-c8ed-4715-b3d3-1aaad9ad6381",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "722e08d6-b3c4-40a5-b103-94841035b3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>δεινοί τινεσ εἰσὶ νουθετεῖν ἑτέρουσ ἀφε...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>οὐκ ἀμφοτέρων ἄρα τῶν καιρῶν διήμαρτον...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>̔ μὲν ἐπίδειξισ οὐδαμῶσ εὐτυχὴσ οὐδὲ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>̓́στι μὲν οὐ σμικρὸν, ὦ ἄνδρεσ σμυρναῖ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>νόμοσ ἐστὶ τοῖσ ̔́λλησι παλαιὸσ, οἶμαι ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>̓σαῖοσ δὲ ὁ δημοσθένουσ καθηγησάμενοσ κ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>̔ητορική ἐστι δύναμισ τεχνικὴ πιθανοῦ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>περὶ δεινάρχου τοῦ ῥήτοροσ οὐδὲν εἰρ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>*************** δικανικοῖσ μὲν οὖν ο...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>‘δῶρόν τοι καὶ ἐγώ, τέκνον φίλε, τ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    δεινοί τινεσ εἰσὶ νουθετεῖν ἑτέρουσ ἀφε...\n",
       "1    οὐκ ἀμφοτέρων ἄρα τῶν καιρῶν διήμαρτον...\n",
       "2    ̔ μὲν ἐπίδειξισ οὐδαμῶσ εὐτυχὴσ οὐδὲ ...\n",
       "3    ̓́στι μὲν οὐ σμικρὸν, ὦ ἄνδρεσ σμυρναῖ...\n",
       "4    νόμοσ ἐστὶ τοῖσ ̔́λλησι παλαιὸσ, οἶμαι ...\n",
       "..                                                 ...\n",
       "154    ̓σαῖοσ δὲ ὁ δημοσθένουσ καθηγησάμενοσ κ...\n",
       "155      ̔ητορική ἐστι δύναμισ τεχνικὴ πιθανοῦ...\n",
       "156    περὶ δεινάρχου τοῦ ῥήτοροσ οὐδὲν εἰρ...\n",
       "157        *************** δικανικοῖσ μὲν οὖν ο...\n",
       "158       ‘δῶρόν τοι καὶ ἐγώ, τέκνον φίλε, τ...\n",
       "\n",
       "[159 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "747a6480-9209-476e-bbe7-07a647110384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the dataframe to a list of strings\n",
    "df = data['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82362c47-b041-4307-bbdc-0b7dd834f5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    }
   ],
   "source": [
    "#print the number of rows in the dataframe\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a0f2808-c948-472a-9415-d3e1a9d8013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the data and prepare it for model input\n",
    "inputs = tokenizer(df, return_tensors = 'pt', max_length = 512, truncation = True, padding = 'max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c787401a-f568-4c4d-8e9d-d3e0fcd8191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the labels by cloning the input IDs\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4ff9a6b-a111-4166-973a-a4dc7f570c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a random array to decide which tokens to mask\n",
    "rand = torch.rand(inputs.input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9ed66a5-9812-415b-968e-2e2f98103481",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arr = rand < 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9474659f-b4fb-4377-a437-826f34144578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  ...,  True,  True,  True],\n",
       "        [False,  True,  True,  ...,  True,  True,  True],\n",
       "        [False,  True,  True,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False,  True,  True,  ...,  True,  True,  True],\n",
       "        [False,  True,  True,  ...,  True,  True,  True],\n",
       "        [False,  True,  True,  ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids != 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aad0f58c-6f64-4059-843a-1fc9a7b829fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15% of tokens will be masked\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f65a8c48-7bee-4bc6-be38-cade55032203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6e45659-2729-4a32-9931-dafedef213b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a selection array to apply the mask to the input IDs\n",
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f2b5880-ea9d-4e6f-ac8c-9bd817d3d4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3,\n",
       "  5,\n",
       "  7,\n",
       "  13,\n",
       "  20,\n",
       "  42,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  57,\n",
       "  70,\n",
       "  80,\n",
       "  82,\n",
       "  87,\n",
       "  92,\n",
       "  107,\n",
       "  120,\n",
       "  124,\n",
       "  126,\n",
       "  134,\n",
       "  140,\n",
       "  142,\n",
       "  145,\n",
       "  154,\n",
       "  160,\n",
       "  164,\n",
       "  170,\n",
       "  174,\n",
       "  179,\n",
       "  195,\n",
       "  199,\n",
       "  217,\n",
       "  223,\n",
       "  227,\n",
       "  246,\n",
       "  249,\n",
       "  254,\n",
       "  257,\n",
       "  266,\n",
       "  269,\n",
       "  277,\n",
       "  278,\n",
       "  281,\n",
       "  291,\n",
       "  293,\n",
       "  299,\n",
       "  304,\n",
       "  314,\n",
       "  319,\n",
       "  322,\n",
       "  323,\n",
       "  329,\n",
       "  341,\n",
       "  342,\n",
       "  348,\n",
       "  357,\n",
       "  359,\n",
       "  370,\n",
       "  380,\n",
       "  387,\n",
       "  390,\n",
       "  391,\n",
       "  398,\n",
       "  405,\n",
       "  409,\n",
       "  413,\n",
       "  418,\n",
       "  424,\n",
       "  425,\n",
       "  440,\n",
       "  445,\n",
       "  450,\n",
       "  457,\n",
       "  460,\n",
       "  465,\n",
       "  468,\n",
       "  474,\n",
       "  497,\n",
       "  506,\n",
       "  508,\n",
       "  509],\n",
       " [4,\n",
       "  12,\n",
       "  16,\n",
       "  28,\n",
       "  36,\n",
       "  41,\n",
       "  50,\n",
       "  56,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  76,\n",
       "  84,\n",
       "  90,\n",
       "  94,\n",
       "  109,\n",
       "  110,\n",
       "  116,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  130,\n",
       "  142,\n",
       "  158,\n",
       "  165,\n",
       "  168,\n",
       "  175,\n",
       "  180,\n",
       "  206,\n",
       "  207,\n",
       "  219,\n",
       "  226,\n",
       "  229,\n",
       "  236,\n",
       "  255,\n",
       "  259,\n",
       "  264,\n",
       "  268,\n",
       "  273,\n",
       "  288,\n",
       "  291,\n",
       "  295,\n",
       "  302,\n",
       "  306,\n",
       "  307,\n",
       "  308,\n",
       "  314,\n",
       "  316,\n",
       "  323,\n",
       "  325,\n",
       "  326,\n",
       "  329,\n",
       "  357,\n",
       "  362,\n",
       "  366,\n",
       "  370,\n",
       "  376,\n",
       "  384,\n",
       "  385,\n",
       "  394,\n",
       "  410,\n",
       "  414,\n",
       "  424,\n",
       "  428,\n",
       "  431,\n",
       "  437,\n",
       "  455,\n",
       "  469,\n",
       "  486,\n",
       "  497,\n",
       "  501,\n",
       "  509],\n",
       " [2,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  26,\n",
       "  35,\n",
       "  60,\n",
       "  61,\n",
       "  80,\n",
       "  96,\n",
       "  99,\n",
       "  108,\n",
       "  120,\n",
       "  124,\n",
       "  131,\n",
       "  133,\n",
       "  139,\n",
       "  140,\n",
       "  146,\n",
       "  148,\n",
       "  149,\n",
       "  152,\n",
       "  157,\n",
       "  167,\n",
       "  171,\n",
       "  185,\n",
       "  190,\n",
       "  207,\n",
       "  208,\n",
       "  219,\n",
       "  221,\n",
       "  223,\n",
       "  225,\n",
       "  231,\n",
       "  235,\n",
       "  237,\n",
       "  238,\n",
       "  242,\n",
       "  256,\n",
       "  267,\n",
       "  272,\n",
       "  276,\n",
       "  279,\n",
       "  281,\n",
       "  288,\n",
       "  292,\n",
       "  293,\n",
       "  295,\n",
       "  320,\n",
       "  323,\n",
       "  331,\n",
       "  339,\n",
       "  342,\n",
       "  347,\n",
       "  352,\n",
       "  354,\n",
       "  358,\n",
       "  368,\n",
       "  369,\n",
       "  374,\n",
       "  378,\n",
       "  386,\n",
       "  395,\n",
       "  401,\n",
       "  424,\n",
       "  435,\n",
       "  436,\n",
       "  442,\n",
       "  445,\n",
       "  446,\n",
       "  447,\n",
       "  451,\n",
       "  471,\n",
       "  473,\n",
       "  474,\n",
       "  483,\n",
       "  486],\n",
       " [2,\n",
       "  4,\n",
       "  7,\n",
       "  17,\n",
       "  20,\n",
       "  26,\n",
       "  35,\n",
       "  36,\n",
       "  41,\n",
       "  42,\n",
       "  44,\n",
       "  47,\n",
       "  49,\n",
       "  52,\n",
       "  54,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  63,\n",
       "  64,\n",
       "  76,\n",
       "  80,\n",
       "  88,\n",
       "  91,\n",
       "  93,\n",
       "  95,\n",
       "  106,\n",
       "  111,\n",
       "  124,\n",
       "  134,\n",
       "  140,\n",
       "  151,\n",
       "  152,\n",
       "  155,\n",
       "  174,\n",
       "  189,\n",
       "  197,\n",
       "  202,\n",
       "  204,\n",
       "  218,\n",
       "  223,\n",
       "  224,\n",
       "  227,\n",
       "  244,\n",
       "  255,\n",
       "  258,\n",
       "  264,\n",
       "  271,\n",
       "  272,\n",
       "  275,\n",
       "  305,\n",
       "  313,\n",
       "  326,\n",
       "  331,\n",
       "  343,\n",
       "  344,\n",
       "  350,\n",
       "  359,\n",
       "  360,\n",
       "  362,\n",
       "  364,\n",
       "  371,\n",
       "  373,\n",
       "  374,\n",
       "  399,\n",
       "  407,\n",
       "  410,\n",
       "  422,\n",
       "  438,\n",
       "  445,\n",
       "  450,\n",
       "  451,\n",
       "  467,\n",
       "  486,\n",
       "  490,\n",
       "  502],\n",
       " [2,\n",
       "  13,\n",
       "  14,\n",
       "  18,\n",
       "  19,\n",
       "  21,\n",
       "  25,\n",
       "  33,\n",
       "  35,\n",
       "  37,\n",
       "  41,\n",
       "  52,\n",
       "  57,\n",
       "  63,\n",
       "  69,\n",
       "  73,\n",
       "  75,\n",
       "  79,\n",
       "  83,\n",
       "  85,\n",
       "  91,\n",
       "  94,\n",
       "  101,\n",
       "  103,\n",
       "  104,\n",
       "  108,\n",
       "  117,\n",
       "  121,\n",
       "  124,\n",
       "  134,\n",
       "  136,\n",
       "  144,\n",
       "  148,\n",
       "  169,\n",
       "  178,\n",
       "  180,\n",
       "  190,\n",
       "  204,\n",
       "  218,\n",
       "  226,\n",
       "  240,\n",
       "  246,\n",
       "  248,\n",
       "  253,\n",
       "  285,\n",
       "  290,\n",
       "  292,\n",
       "  293,\n",
       "  313,\n",
       "  314,\n",
       "  329,\n",
       "  335,\n",
       "  346,\n",
       "  349,\n",
       "  357,\n",
       "  361,\n",
       "  366,\n",
       "  369,\n",
       "  380,\n",
       "  398,\n",
       "  408,\n",
       "  412,\n",
       "  426,\n",
       "  432,\n",
       "  439,\n",
       "  447,\n",
       "  455,\n",
       "  460,\n",
       "  462,\n",
       "  466,\n",
       "  467,\n",
       "  471,\n",
       "  477,\n",
       "  485,\n",
       "  486,\n",
       "  493,\n",
       "  498]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64236bb7-40ae-4cb9-86ef-5b9e970a9666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the mask (replace tokens with the mask token ID 103)\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92349c66-f6ed-4fa5-a5b1-69a7d11fcb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 24688,   269,  ...,   103,  4858,   102],\n",
       "        [  101,  4858,  2361,  ...,   103,   287,   102],\n",
       "        [  101,   351,   103,  ...,  3258,   279,   102],\n",
       "        ...,\n",
       "        [  101,   518, 17327,  ..., 12856,   281,   102],\n",
       "        [  101,   117,   117,  ...,   575,   273,   102],\n",
       "        [  101,   294,  2207,  ...,   877,  3436,   102]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "759efad7-68ff-4385-849e-1a9136d6001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a custom dataset class to handle the input encodings\n",
    "class GreekDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a62b5a80-72ad-4a11-8b35-9b876fe10347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataset and dataloader for the inputs\n",
    "dataset = GreekDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "072a0b9a-26d2-4c24-a635-f2733d70c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec15831c-5ec1-489c-bd43-ee9b48b53192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=35000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15791c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "model_path = '../mlm_transfer/model'  #model save path\n",
    "tokenizer_path = '../mlm_transfer/tokenizer'   #tokenizer save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afece194-fb7b-453c-ab0e-aa147268afa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vvybornaya/.conda/envs/my_py_env2/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]/tmp/job-1946133/ipykernel_221610/4120075177.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|██████████| 10/10 [00:11<00:00,  1.15s/it, loss=4.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved for epoch 0\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4) \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad() \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    model.save_pretrained(os.path.join(model_path, f'epoch_{epoch}'))\n",
    "    tokenizer.save_pretrained(os.path.join(tokenizer_path, f'epoch_{epoch}'))\n",
    "\n",
    "    print(f'Model and tokenizer saved for epoch {epoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6e788de-14b8-4bf4-bc2d-59d0a9b6e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here goes roberta mlm transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81f4076d-d451-42cc-b31d-7b7517879edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"bowphs/GreBerta\")\n",
    "model = RobertaForMaskedLM.from_pretrained(\"bowphs/GreBerta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30a9fd68-0221-403b-931a-ad119cffa9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=52000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "model_path = '../mlm_transfer/model_roberta'  \n",
    "tokenizer_path = '../mlm_transfer/tokenizer_roberta'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b25df275-65f4-413f-baf5-a865dffb1730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vvybornaya/.conda/envs/my_py_env2/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]/tmp/job-1946133/ipykernel_221610/4120075177.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|██████████| 10/10 [00:06<00:00,  1.55it/s, loss=1.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved for epoch 0\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4)  \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()  \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    model.save_pretrained(os.path.join(model_path, f'epoch_{epoch}'))\n",
    "    tokenizer.save_pretrained(os.path.join(tokenizer_path, f'epoch_{epoch}'))\n",
    "\n",
    "    print(f'Model and tokenizer saved for epoch {epoch}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
